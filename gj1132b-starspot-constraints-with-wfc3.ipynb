{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates contraints on starspot contamination for GJ 1132, based on observations from Hubble/WFC3 and ground-based telescopes, as presented in Libby-Roberts et al. (2022). It was written by Zach Berta-Thompson in spring 2021, and revised in spring 2022.\n",
    "\n",
    "We'll start by importing tools from the [`starspot-backlights`](https://github.com/zkbt/starspot-backlights) package, which contains the basic modeling framework and tools. You can install them via `pip install starspot-backlights`. The current version is `0.0.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starspotbacklights import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set up the data we will use as a constraint. We'll make a dictionary, called `all_data`, and populate it with a few different kinds of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data += Out-of-Transit Modulations\n",
    "\n",
    "First, we'll add some information about the amplitude of the out-of-transit modulations cause by the rotation of the star. This is expressed as, approximately, the semi-amplitude of the flux variations in one or more photometric bandpasses (which may be custom, effectively spectroscopic, bandpasses).\n",
    "\n",
    "In the case of GJ1132, the semi-amplitude (= half the peak-to-peak ampltiude) seems to be about 1% by visual inspection of its out-of-transit light curve. We'll give it an approximate error bar of about 0.2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a data point for the amplitude of out of transit modulations\n",
    "oot = pd.DataFrame({'amplitude':0.01, \n",
    "                    'filter':MEarth(),\n",
    "                    'amplitude-error':0.002}, index=[0])\n",
    "\n",
    "oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this out-of-transit table to the data being fit\n",
    "all_data['oot'] = oot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data += The Overall Spectrum of the Star\n",
    "Next, let's make sure that the integrated flux from our multi-component stellar surface adds up to be something that looks like the real star. For example, we want to exclude models were both the \"unspotted\" and the \"spotted\" photosphere have temperatures that are both way warmer or way colder than the actual temperature of the star. \n",
    "\n",
    "The semi-kludgy way to do this is to make sure that the integrated surface flux of the star works out to have something near the effective temperature of the star as determined from its bolometric flux. The more precise way to do this would likely be to try to reproduce the actual absolute spectrum of the star for at least some wavelengths -- let's consider that TBD!\n",
    "\n",
    "In the case of GJ1132, the effective temperature of the star (from Berta-Thompson + Bonfils + ...) is $3270\\pm140$K. We'll use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put in one data point for the effective temperature of the star\n",
    "teff = pd.DataFrame({'teff':3270, \n",
    "                     'teff-error':140}, index=[0])\n",
    "teff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this average stellar spectrum constraint to the data being fit\n",
    "all_data['teff'] = teff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data += The Observed Transmission Spectrum\n",
    "\n",
    "Next, let's include some observations of the transit depth as a function of wavelength. Those constrain a unique combination of starspot parameters and are particularly sensitive to the total spot covering fraction $f$.\n",
    "\n",
    "In the case of GJ1132, let's start with including the depths from Jessica Libby-Roberts' WFC3 paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Jessica Libby-Roberts' table of transit depths from WFC3\n",
    "wfc3_depths = pd.read_csv('gj1132b-depth-data/hst_depths.tex', delimiter='\\t',\n",
    "                   names=['wavelength', 'depth', 'depth-error'])\n",
    "\n",
    "# create some filters associated with each wavelength bin\n",
    "dw = np.round(np.median(np.diff(wfc3_depths['wavelength'])), decimals=5)\n",
    "wfc3_depths['filter'] = [Filter(w*1000, dw*1000) for w in wfc3_depths['wavelength']]\n",
    "\n",
    "wfc3_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to the data constraints\n",
    "all_data['depth'] = wfc3_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also add in Hannah Diamond-Lowe's [LDSS3C transit depths](https://ui.adsabs.harvard.edu/abs/2018AJ....156...42D/abstract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Hannah Diamond-Lowe's table from LDSSC3\n",
    "ldss3c = pd.read_csv('gj1132b-depth-data/diamondlowe_depths.txt', delimiter=',',\n",
    "                   names=['wavelength', 'depth', 'depth-error'])\n",
    "\n",
    "# create some filters associated with each wavelength bin\n",
    "dw = np.round(np.median(np.diff(ldss3c['wavelength'])), decimals=5)\n",
    "ldss3c['filter'] = [Filter(w*1000, dw*1000) for w in ldss3c['wavelength']]\n",
    "\n",
    "ldss3c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have some uncertainties about the absolute level of the transit depths for these data, we will include them as `relative-depth`. This is a kludge that we added to the code; these depths will be allowed to move up and down as a group went fitting. (If you'll have more than two different depth datasets that will all need to shift relative to each other, you'll need to modify the `starspot-backlights` definitions. Sorry!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['relative-depth'] = ldss3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in all_data:\n",
    "    print(f'There are {len(all_data[k]):2} \"{k}\" data points.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer Some Starspot Parameters\n",
    "\n",
    "Now that we've defined all that useful data, let's run a little MCMC to explore how well we can reproduce the provided data with a simple model of a spotted star. This particular model includes a gentle prior on how to connect the time-variable component of the spot-covering fraction $\\Delta f$ to overall average starspot-covering fraction $f$. It's set in a kind-of-kludgy Poisson fashion by the fractional covering area of one starspot $f_1$. \n",
    "\n",
    "We'll use MCMC to sample from the probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample with an increasing number of steps \n",
    "for N in [100, 1000, 10000]:\n",
    "    # sample using different subsets of the data\n",
    "    for to_include in [['oot', 'teff', 'depth', 'relative-depth'],\n",
    "                       ['oot', 'teff', 'depth']]:\n",
    "\n",
    "        # create a unique label for this subset of data\n",
    "        label = '+'.join(to_include)\n",
    "        data_to_use = {k:all_data[k] for k in to_include}\n",
    "        print(f'{label} with {N} steps\\n' + '-'*10)\n",
    "\n",
    "        # create a backlight object, which we'll use to sample\n",
    "        b = Backlight(data_to_use, \n",
    "                      include_poisson=True, \n",
    "                      max_temperature_offset=0.25, \n",
    "                      stellar_radius=0.2105, \n",
    "                      planet_radius=1.130,\n",
    "                      logg=5.0) \n",
    "\n",
    "        # create (or load already generated) MCMC samples\n",
    "        b.sample(N, N)\n",
    "\n",
    "        # make a multipanel plot of the data and model parameters\n",
    "        b.plot_everything()\n",
    "        b.legend_amplitude.get_texts()[0].set_text('MEarth')\n",
    "        b.legend_depth.get_texts()[0].set_text('WFC3')\n",
    "        if 'relative-depth' in to_include:\n",
    "            b.legend_depth.get_texts()[1].set_text('Magellan')\n",
    "        plt.savefig(f'GJ1132b-starspots-everything-{label}-{N}.pdf');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's ask the question of whether it's possible to hide the signal of a H-rich atmosphere by canceling out its transmission spectrum with an unfortunate arrangement of spots. To do this, we'll make a fake dataset with flipped a H-rich transmission spectrum injected into it. If we can model that well with spots, then spots could cancel out a real transmission spectrum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a table of model transit depths\n",
    "solar_model_depths = pd.read_csv('gj1132b-depth-data/100xsolar_binned.txt', names=['wavelength', 'depth'], delimiter=' ')\n",
    "\n",
    "# make a fake set of transit depths\n",
    "fake_wfc3_depths = copy.deepcopy(wfc3_depths)\n",
    "simulation = np.interp(wfc3_depths['wavelength'], solar_model_depths['wavelength'], solar_model_depths['depth'])\n",
    "fake_wfc3_depths['depth'] -= (simulation - np.mean(simulation))\n",
    "\n",
    "# make a fake complete dataset, with these fake depths\n",
    "faked_all_data = copy.deepcopy(all_data)\n",
    "faked_all_data['depth'] = fake_wfc3_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample with an increasing number of steps \n",
    "for N in [100, 1000, 10000]:\n",
    "    # sample using different subsets of the data\n",
    "    for to_include in [['oot', 'teff', 'depth']]:\n",
    "\n",
    "        # create a unique label for this subset of data\n",
    "        label = '+'.join(to_include)\n",
    "        data_to_use = {k:faked_all_data[k] for k in to_include}\n",
    "        print(f'{label} with {N} steps\\n' + '-'*10)\n",
    "        \n",
    "        # create a backlight object, which we'll use to sample\n",
    "        b = Backlight(data_to_use, \n",
    "                      include_poisson=True, \n",
    "                      max_temperature_offset=0.25, \n",
    "                      stellar_radius=0.2105, \n",
    "                      planet_radius=1.130,\n",
    "                      logg=5.0,\n",
    "                      label='fake100xsolar') \n",
    "        \n",
    "        # create (or load already generated) MCMC samples\n",
    "        b.sample(N, N)\n",
    "        \n",
    "        # make a multipanel plot of the data and model parameters\n",
    "        b.plot_everything()\n",
    "        b.legend_amplitude.get_texts()[0].set_text('MEarth')\n",
    "        b.legend_depth.get_texts()[0].set_text('WFC3')\n",
    "                \n",
    "        plt.savefig(f'GJ1132b-starspots-everything-{label}-{N}-fake100xsolar.pdf');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
