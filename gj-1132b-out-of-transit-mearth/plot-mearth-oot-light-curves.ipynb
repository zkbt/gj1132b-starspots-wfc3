{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook plots the MEarth light curves for GJ 1132b, downloaded from the MEarth data release page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, numpy as np, matplotlib.pyplot as plt\n",
    "from astropy.io.ascii import read\n",
    "from lightkurve import LightCurve\n",
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "from exoatlas.visualizations.ink_errorbar import ink_errorbar, one2another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEarth-South's `tel13` and `tel16` were the two telescopes that continuously monitored the brightnes sof GJ1132 over many years, including both in-transit and out-of-transit observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telescopes = [13, 16]\n",
    "files = [f'mearth-light-curves/2MASSJ10145184-4709244_tel{t}_2014-2019.txt' for t in telescopes]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to trim out the high-cadence transit observations, so they don't too strongly affect our binned averages with lots and lots of observations all at one time (to say nothing of the transit itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_high_cadence(lc):\n",
    "    '''\n",
    "    Trim out high-cadence (= targeted transit) observations.\n",
    "    '''\n",
    "    \n",
    "    # identify which moments include >N data points in <threshold days\n",
    "    N  = 30\n",
    "    threshold = 0.5/24\n",
    "    time_for_N = lc.time.value[N:] - lc.time.value[:-N] \n",
    "\n",
    "    # idenitify which points are follow\n",
    "    followed_by_high_cadence = np.nonzero(time_for_N < threshold)[0]\n",
    "    \n",
    "    # create an array of which datapoints to include\n",
    "    ok = np.ones_like(lc.time.value).astype(np.bool)\n",
    "\n",
    "    # remove high cadence points\n",
    "    ok[followed_by_high_cadence] = False\n",
    "    ok[followed_by_high_cadence + N] = False\n",
    "    return lc[ok]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are both the `uncorrected` raw light curves, and the `corrected` light curves where we've made an effort to correct for various instrumental systematics like meridian flips or the precipitable water-vapor common mode. Let's look at both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epochs():\n",
    "    visits = np.arange(1,6)\n",
    "    transit_epochs = np.array([862.19257, 1020.19808, 1077.21151, 1080.46896, 1083.72617])# + 2457000\n",
    "    colors = ['cornflowerblue', \n",
    "              'crimson', \n",
    "              'seagreen', \n",
    "              'chocolate',\n",
    "              'orchid']\n",
    "    for v, e, c in zip(visits, transit_epochs, colors):\n",
    "        plt.axvline(e, color=c, zorder=-10, label=f'Visit {v}')\n",
    "        #plt.text(e, 1.02, f'Visit {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = dict(Uncorrected='Mag', Corrected='Corr_Mag') \n",
    "\n",
    "for option in colnames:\n",
    "\n",
    "    lcs= {}\n",
    "    for t, f in zip(telescopes, files):\n",
    "        lc = read(f, data_start=54, names='BJD           Mag         e_Mag       tExp    DMag    FWHM   Ellip Airmass X         Y         Angle   Sky      Peak  S  V  R F CM        Corr_Mag'.split())\n",
    "        lcs[t] = LightCurve(time=Time(lc['BJD']-2457000.0 , format='btjd'), \n",
    "                            flux=10**(-0.4*lc[colnames[option]]), \n",
    "                            flux_err=1.086*lc['e_Mag'])\n",
    "\n",
    "    \n",
    "    fi, ax = plt.subplots(1,1, figsize=(8.5,2.5))\n",
    "    colors = {13:'#1f77b4', 16: '#ff7f0e'}# {13:'brown', 16: 'dimgray'}\n",
    "    for t in lcs:\n",
    "        lc = remove_high_cadence(lcs[t])\n",
    "        binned = lc.bin(1*u.day, aggregate_func=np.nanmedian).remove_nans()\n",
    "        ink_errorbar(x=binned.time.value, \n",
    "                     y=binned.flux.value,\n",
    "                     xerr=np.zeros_like(binned.time.value),\n",
    "                     yerr=binned.flux_err.value, \n",
    "                     c=1/binned.flux_err.value**2,\n",
    "                     cmap=one2another('white', colors[t]),\n",
    "                     vmax=1e6, vmin=1e3)\n",
    "    span = 0.025\n",
    "    plt.ylim(1-span, 1+span)\n",
    "    #plt.legend()\n",
    "\n",
    "    plt.xlabel('Time - 2457000 [BTJD days]')\n",
    "    plt.ylabel(f'Relative Flux')\n",
    "    plot_epochs()\n",
    "    plt.legend(bbox_to_anchor=(1,1), frameon=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'GJ1132-error-bars-{option}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! The 120-130 day rotation period seems to show up particularly clearly in the last few cycles from ~1000-1750 days. Overall, the peak-to-peak modulation amplitude is about 1-2%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
